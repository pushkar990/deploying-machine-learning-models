| Pattern Name         | Columns Included                                                             | Notes                                       |
| -------------------- | ---------------------------------------------------------------------------- | ------------------------------------------- |
| Pattern_Basic        | aprdrgcode + soi_indicator + dischargestatuscode                             | High support, coarse overview               |
| Pattern_Standard     | aprdrgcode + soi_indicator + dischargestatuscode + diag1                     | Standard SME pattern                        |
| Pattern_Dx           | aprdrgcode + soi_indicator + dischargestatuscode + diag1–diag6               | Adds clinical specificity, medium support   |
| Pattern_Full         | aprdrgcode + soi_indicator + dischargestatuscode + diag1–diag6 + proc1–proc6 | More granular, medium support               |
| Pattern_LOS          | soi_indicator + dischargestatuscode + LOS_bin                                | Secondary signal                            |
| Pattern_Paid         | soi_indicator + dischargestatuscode + Paid_bin                               | Secondary signal                            |
| Pattern_LOS_Paid     | soi_indicator + dischargestatuscode + LOS_bin + Paid_bin                     | Exploratory only                            |
| Pattern_Drg_LOS      | aprdrgcode + soi_indicator + dischargestatuscode + LOS_bin                   | Combines clinical + LOS, secondary          |
| Pattern_Drg_Paid     | aprdrgcode + soi_indicator + dischargestatuscode + Paid_bin                  | Combines clinical + Paid, secondary         |
| Pattern_Drg_LOS_Paid | aprdrgcode + soi_indicator + dischargestatuscode + LOS_bin + Paid_bin        | Combines clinical + LOS + Paid, exploratory |



import pandas as pd  # For data manipulation
import numpy as np   # For numerical operations

# -----------------------------
# Step 0: Load data
# -----------------------------
df = pd.read_csv("claims.csv")  # Load your claims dataset

# Separate audited (SME-selected) vs non-audited (unaudited) claims
audited = df[~df['find'].isna()].copy()   # Audited claims have 'find' not NaN
unaudited = df[df['find'].isna()].copy()  # Non-audited claims

# Define diagnosis and procedure columns (top 6)
dx_cols = [f'diag{i}' for i in range(1,7)]
proc_cols = [f'proc{i}' for i in range(1,7)]

# -----------------------------
# Step 1: Bin numeric features
# -----------------------------
# Bin LOS into categories for pattern analysis
los_bins = [0,2,5,10,15,1000]  # Bin edges
los_labels = ['VeryShort','Short','Medium','Long','VeryLong']  # Labels
audited['LOS_bin'] = pd.cut(audited['los'], bins=los_bins, labels=los_labels)
unaudited['LOS_bin'] = pd.cut(unaudited['los'], bins=los_bins, labels=los_labels)

# Bin total paid amount into categories
paid_bins = [0,10000,50000,100000,1000000]  # Bin edges
paid_labels = ['Low','Medium','High','VeryHigh']  # Labels
audited['Paid_bin'] = pd.cut(audited['totalpaidamount'], bins=paid_bins, labels=paid_labels)
unaudited['Paid_bin'] = pd.cut(unaudited['totalpaidamount'], bins=paid_bins, labels=paid_labels)

# -----------------------------
# Step 2: Helper function to create patterns
# -----------------------------
def make_pattern(row, prefix_cols=[], dx_cols=[], proc_cols=[], include_proc=False, add_los=False, add_paid=False):
    """
    Constructs a pattern string from multiple columns.
    prefix_cols: always included (e.g., aprdrgcode, soi_indicator, discharge)
    dx_cols: list of diagnosis columns
    proc_cols: list of procedure columns
    include_proc: if True, include proc_cols
    add_los: if True, include LOS_bin
    add_paid: if True, include Paid_bin
    """
    parts = []  # List to hold pattern components

    # Add prefix columns
    for c in prefix_cols:
        parts.append(str(row[c]))

    # Add diagnosis columns if provided
    if dx_cols:
        dx_part = "_".join([str(row[c]) if pd.notna(row[c]) else "NA" for c in dx_cols])
        parts.append(dx_part)

    # Add procedure columns if requested
    if include_proc and proc_cols:
        proc_part = "_".join([str(row[c]) if pd.notna(row[c]) else "NA" for c in proc_cols])
        parts.append(proc_part)

    # Add LOS_bin if requested
    if add_los:
        parts.append(str(row['LOS_bin']))

    # Add Paid_bin if requested
    if add_paid:
        parts.append(str(row['Paid_bin']))

    # Join all parts with "_" separator
    return "_".join(parts)

# -----------------------------
# Step 3: Create patterns for audited data
# -----------------------------
# Main clinical patterns
audited['Pattern_Basic'] = audited.apply(lambda x: make_pattern(x, prefix_cols=['aprdrgcode','soi_indicator','dischargestatuscode']), axis=1)
audited['Pattern_Standard'] = audited.apply(lambda x: make_pattern(x, prefix_cols=['aprdrgcode','soi_indicator','dischargestatuscode'], dx_cols=['diag1']), axis=1)
audited['Pattern_Dx'] = audited.apply(lambda x: make_pattern(x, prefix_cols=['aprdrgcode','soi_indicator','dischargestatuscode'], dx_cols=dx_cols), axis=1)
audited['Pattern_Full'] = audited.apply(lambda x: make_pattern(x, prefix_cols=['aprdrgcode','soi_indicator','dischargestatuscode'], dx_cols=dx_cols, proc_cols=proc_cols, include_proc=True), axis=1)

# Secondary signals based on LOS / Paid / Discharge
audited['Pattern_LOS'] = audited.apply(lambda x: make_pattern(x, prefix_cols=['soi_indicator','dischargestatuscode'], add_los=True), axis=1)
audited['Pattern_Paid'] = audited.apply(lambda x: make_pattern(x, prefix_cols=['soi_indicator','dischargestatuscode'], add_paid=True), axis=1)
audited['Pattern_LOS_Paid'] = audited.apply(lambda x: make_pattern(x, prefix_cols=['soi_indicator','dischargestatuscode'], add_los=True, add_paid=True), axis=1)

# Hybrid patterns combining APR-DRG with LOS/Paid
audited['Pattern_Drg_LOS'] = audited.apply(lambda x: make_pattern(x, prefix_cols=['aprdrgcode','soi_indicator','dischargestatuscode'], add_los=True), axis=1)
audited['Pattern_Drg_Paid'] = audited.apply(lambda x: make_pattern(x, prefix_cols=['aprdrgcode','soi_indicator','dischargestatuscode'], add_paid=True), axis=1)
audited['Pattern_Drg_LOS_Paid'] = audited.apply(lambda x: make_pattern(x, prefix_cols=['aprdrgcode','soi_indicator','dischargestatuscode'], add_los=True, add_paid=True), axis=1)

# List of all patterns for iteration
pattern_cols = [
    'Pattern_Basic','Pattern_Standard','Pattern_Dx','Pattern_Full',
    'Pattern_LOS','Pattern_Paid','Pattern_LOS_Paid',
    'Pattern_Drg_LOS','Pattern_Drg_Paid','Pattern_Drg_LOS_Paid'
]

# -----------------------------
# Step 4: Global patterns (all audited claims)
# -----------------------------
global_stats = []

for pat_col in pattern_cols:
    # Group by pattern
    stats = audited.groupby(pat_col).agg(
        Total=('find','count'),  # number of claims with this pattern
        Hits=('find','sum')      # number of claims with findings
    ).reset_index()
    
    overall_hit_rate = audited['find'].mean()  # baseline hit rate across all claims
    stats['Support'] = stats['Total'] / len(audited)  # pattern frequency / total claims
    stats['HitRate'] = stats['Hits'] / stats['Total']  # pattern-specific hit rate
    stats['Lift'] = stats['HitRate'] / overall_hit_rate if overall_hit_rate > 0 else 0  # relative to baseline
    stats['Pattern_Type'] = pat_col
    stats['Client'] = 'ALL'
    global_stats.append(stats)

global_stats_df = pd.concat(global_stats, axis=0)

# -----------------------------
# Step 5: Client-specific patterns
# -----------------------------
client_stats = []

for client in audited['clientname'].unique():
    client_data = audited[audited['clientname'] == client].copy()
    overall_hit_rate = client_data['find'].mean()  # baseline per client
    
    for pat_col in pattern_cols:
        stats = client_data.groupby(pat_col).agg(
            Total=('find','count'),
            Hits=('find','sum')
        ).reset_index()
        stats['Support'] = stats['Total'] / len(client_data)
        stats['HitRate'] = stats['Hits'] / stats['Total']
        stats['Lift'] = stats['HitRate'] / overall_hit_rate if overall_hit_rate > 0 else 0
        stats['Pattern_Type'] = pat_col
        stats['Client'] = client
        client_stats.append(stats)

client_stats_df = pd.concat(client_stats, axis=0)

# -----------------------------
# Step 6: Test patterns on non-audited claims
# -----------------------------
for pat_col in pattern_cols:
    # Generate same pattern structure for unaudited claims
    # Note: for simplicity, only uses the same columns logic as audited patterns
    if 'Drg' in pat_col:
        prefix_cols = ['aprdrgcode','soi_indicator','dischargestatuscode']
    elif 'LO' in pat_col or 'Paid' in pat_col:
        prefix_cols = ['soi_indicator','dischargestatuscode']
    else:
        prefix_cols = ['aprdrgcode','soi_indicator','dischargestatuscode']
    
    dx_list = dx_cols if 'Dx' in pat_col and 'Full' not in pat_col else []
    include_proc = 'Full' in pat_col
    add_los = 'LOS' in pat_col
    add_paid = 'Paid' in pat_col

    unaudited[pat_col] = unaudited.apply(
        lambda x: make_pattern(x, prefix_cols=prefix_cols, dx_cols=dx_list, proc_cols=proc_cols, include_proc=include_proc, add_los=add_los, add_paid=add_paid),
        axis=1
    )

# Count number of unaudited claims matching each pattern
test_stats = []
for pat_col in pattern_cols:
    stats = unaudited.groupby(pat_col).agg(
        NonAuditedCount=('soi_indicator','count')
    ).reset_index()
    stats['Pattern_Type'] = pat_col
    test_stats.append(stats)

unaudited_stats_df = pd.concat(test_stats, axis=0)

# -----------------------------
# Step 7: Save outputs
# -----------------------------
global_stats_df.to_csv("global_pattern_stats.csv", index=False)
client_stats_df.to_csv("client_pattern_stats.csv", index=False)
unaudited_stats_df.to_csv("unaudited_pattern_test.csv", index=False)

print("✅ Global, client-specific, and unaudited pattern stats saved successfully.")
